# Абстрактная Суммаризация Русскоязычных Новостных Текстов (Seq2Seq)

Репозиторий курсовой работы, демонстрирующий разработку и сравнительный анализ трансформерных моделей (ruT5, ruGPT3) для задачи абстрактной суммаризации русскоязычных новостей.

## Описание Проекта

Проект посвящен исследованию и реализации систем автоматической абстрактной суммаризации. Цель – создание моделей, способных генерировать краткие, информативные и фактически точные резюме новостных статей на русском языке. Работа включает полный цикл: от подготовки данных (на основе датасетов Gazeta и XLSum) до дообучения, оценки и сравнительного анализа моделей.

**Ключевые этапы:**
1.  Сбор, объединение и предобработка данных (более 150 тыс. исходных статей).
2.  Фильтрация и формирование выборок (~32 тыс. пар "статья-резюме").
3.  Дообучение (fine-tuning) моделей: `ai-forever/ruT5-base`, `ai-forever/rugpt3small_based_on_gpt2`, `ai-forever/rugpt3medium_based_on_gpt2`.
4.  Количественная оценка с использованием метрик: ROUGE, METEOR, BERTScore, BLEU, CHRF++.
5.  Качественный анализ и сравнение с state-of-the-art контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta`, `csebuetnlp/mT5_multilingual_XLSum`).

## Структура Репозитория

*   `compute_metrics/`: Ноутбуки для расчета метрик и оценки чекпоинтов.
*   `data/`: Исходные файлы датасетов (`gazeta_raw.txt`, `xl_sum_ru.jsonl`).
*   `final_data/`: Обработанные и разделенные датасеты (`test.csv`, `train.csv`, `validation.csv`).
*   `fit_models/`: Ноутбуки для дообучения моделей.
*   `metrics/`: CSV файлы с результатами метрик.
*   `final_inference.ipynb`: Ноутбук для демонстрации генерации резюме лучшими моделями.
*   `prepare_dataset.ipynb`: Ноутбук для полной подготовки данных.

## Основные Результаты

Модель **`ruT5-base` (чекпоинт 20-й эпохи)** продемонстрировала наилучшую производительность среди дообученных моделей и показала высокую конкурентоспособность по сравнению с контрольными, специализированными моделями, даже при генерации более коротких резюме (64 токена против 84-200 у контрольных).

**Ключевые метрики лучших дообученных моделей:**

| Модель         | Чекпоинт      | ROUGE-1 F1 | ROUGE-2 F1 | ROUGE-L F1 | METEOR  | BERTScore F1 | CHRF++  | BLEU    |
|----------------|---------------|------------|------------|------------|---------|--------------|---------|---------|
| **ruT5-base**  | checkpoint-20 | **30.73**  | **15.22**  | **27.94**  | **29.42** | **78.36**    | **40.06** | **10.91** |
| ruGPT3-medium  | checkpoint-20 | 27.03      | 12.51      | 24.48      | 29.05   | 76.18        | 38.83   | 10.72   |
| ruGPT3-small   | checkpoint-40 | 25.77      | 11.92      | 23.32      | 25.62   | 75.65        | 33.39   | 9.56    |

Качественный анализ подтвердил, что `ruT5-base` генерирует более фактически точные и релевантные резюме, в то время как GPT-модели были более склонны к генерации неточной информации ("галлюцинациям").

## Дообученная Модель на Hugging Face Hub

Лучшая дообученная модель (`ruT5-base`, чекпоинт 20) доступна для использования и дальнейших экспериментов на Hugging Face:

**[ruT5-base-rus-news-sum](https://huggingface.co/Xristo/ruT5-base-rus-news-sum)**

