# Абстрактная Суммаризация Русскоязычных Новостных Текстов с Использованием Seq2Seq Моделей

Этот репозиторий содержит материалы курсовой работы, посвященной исследованию и сравнению различных трансформерных моделей на основе архитектуры Sequence-to-Sequence для задачи абстрактной суммаризации новостных текстов на русском языке.

## Описание Проекта

Целью данной работы являлась разработка, обучение и оценка нескольких современных нейросетевых моделей для генерации кратких и информативных резюме русскоязычных новостных статей. Основное внимание было уделено абстрактивному подходу к суммаризации, при котором модель генерирует новый текст, а не просто извлекает фрагменты из оригинала.

**Ключевые этапы работы:**
1.  Анализ теоретических основ задачи суммаризации и архитектур Seq2Seq (T5, GPT, BART/mBART).
2.  Сбор, объединение и предобработка русскоязычных новостных датасетов (Gazeta и XLSum) для формирования обучающей, валидационной и тестовой выборок.
3.  Дообучение (fine-tuning) трех трансформерных моделей:
    *   `ai-forever/ruT5-base`
    *   `ai-forever/rugpt3small_based_on_gpt2`
    *   `sberbank-ai/rugpt3medium_based_on_gpt2`
4.  Количественная оценка качества сгенерированных резюме с использованием стандартных метрик (ROUGE, METEOR, BERTScore, BLEU, CHRF++).
5.  Качественный анализ полученных результатов и сравнение моделей между собой, а также с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta`, `csebuetnlp/mT5_multilingual_XLSum`).

## Технологический Стек

*   **Язык программирования:** Python
*   **Основные библиотеки:**
    *   PyTorch
    *   Hugging Face Transformers (для моделей, токенизаторов, обучения)
    *   Hugging Face Datasets (для работы с данными)
    *   Pandas (для манипуляции данными)
    *   NLTK (для некоторых метрик и токенизации при оценке)
    *   Scikit-learn (для разделения данных)
    *   Rouge, BERT-Score (для метрик оценки)
*   **Среда разработки:** Jupyter Notebook (Google Colab для обучения на GPU)

## Структура Репозитория

*   `data/`: Директория для хранения исходных и обработанных датасетов (может быть исключена из Git через `.gitignore`, если файлы большие).
    *   `final_data/`: Содержит `train.csv`, `validation.csv`, `test.csv`.
*   `notebooks/`: Jupyter ноутбуки с кодом для каждого этапа работы.
    *   `01_data_preparation.ipynb`: Загрузка, очистка, объединение и фильтрация данных.
    *   `02_train_ruT5_base.ipynb`: Обучение модели ruT5-base.
    *   `03_train_ruGPT3_small.ipynb`: Обучение модели ruGPT3-small.
    *   `04_train_ruGPT3_medium.ipynb`: Обучение модели ruGPT3-medium.
    *   `05_evaluation.ipynb`: Оценка всех моделей, расчет метрик, генерация примеров.
*   `models/`: Директория для сохранения дообученных моделей (чекпоинтов) (может быть исключена из Git).
*   `results/`: Результаты оценки, таблицы с метриками, графики.
*   `src/` (опционально): Вспомогательные скрипты или функции, если они вынесены из ноутбуков.
*   `README.md`: Этот файл.
*   `requirements.txt`: Список зависимостей для установки.
*   `final_course_paper.pdf`: Текст пояснительной записки к курсовой работе (ваш документ).

## Основные Результаты

*   Модель `ruT5-base` (чекпоинт 20-й эпохи) показала наилучшие результаты по большинству автоматических метрик.
*   Качественный анализ подтвердил, что `ruT5-base` генерирует более фактически точные и релевантные резюме по сравнению с дообученными моделями `ruGPT3-small` и `ruGPT3-medium`, которые чаще проявляли склонность к "галлюцинациям".
*   Сравнение с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta` и `csebuetnlp/mT5_multilingual_XLSum`) показало, что дообученная `ruT5-base` достигает сопоставимого, а по некоторым метрикам и превосходящего уровня качества, даже при генерации более коротких резюме.

| Модель         | Лучший Чекпоинт | gen_len | rouge1_f | rouge2_f | rougel_f | bert_score_f1 | chrf++  | bleu    | meteor  |
|----------------|-------------------|---------|----------|----------|----------|---------------|---------|---------|---------|
| ruT5-base      | checkpoint-20     | 29.7094 | 30.7346  | 15.2225  | 27.9426  | 78.3572       | 40.0573 | 10.9116 | 29.4225 |
| ruGPT3-small   | checkpoint-40     | 18.2206 | 25.7682  | 11.9178  | 23.3153  | 75.6450       | 33.3899 | 9.5557  | 25.6184 |
| ruGPT3-medium  | checkpoint-20     | 23.2076 | 27.0257  | 12.5114  | 24.4839  | 76.1750       | 38.8347 | 10.7231 | 29.0458 |

## Возможные Улучшения и Дальнейшая Работа

*   Использование более крупных моделей.
*   Тонкая настройка гиперпараметров и стратегий декодирования.
*   Расширение и улучшение качества обучающих данных.
*   Применение техник для снижения "галлюцинаций" у GPT-моделей.
*   Проведение более масштабной человеческой оценки.


