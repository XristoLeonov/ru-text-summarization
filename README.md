# Абстрактная Суммаризация Русскоязычных Новостных Текстов с Использованием Seq2Seq Моделей

Этот репозиторий содержит материалы курсовой работы, посвященной исследованию и сравнению различных трансформерных моделей на основе архитектуры Sequence-to-Sequence для задачи абстрактной суммаризации новостных текстов на русском языке.

## Описание Проекта

Целью данной работы являлась разработка, обучение и оценка нескольких современных нейросетевых моделей для генерации кратких и информативных резюме русскоязычных новостных статей. Основное внимание было уделено абстрактивному подходу к суммаризации, при котором модель генерирует новый текст, а не просто извлекает фрагменты из оригинала.

**Ключевые этапы работы:**
1.  Анализ теоретических основ задачи суммаризации и архитектур Seq2Seq (T5, GPT, BART/mBART).
2.  Сбор, объединение и предобработка русскоязычных новостных датасетов (Gazeta и XLSum) для формирования обучающей, валидационной и тестовой выборок.
3.  Дообучение (fine-tuning) трех трансформерных моделей:
    *   `ai-forever/ruT5-base`
    *   `ai-forever/rugpt3small_based_on_gpt2`
    *   `sberbank-ai/rugpt3medium_based_on_gpt2`
4.  Количественная оценка качества сгенерированных резюме с использованием стандартных метрик (ROUGE, METEOR, BERTScore, BLEU, CHRF++).
5.  Качественный анализ полученных результатов и сравнение моделей между собой, а также с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta`, `csebuetnlp/mT5_multilingual_XLSum`).

## Технологический Стек

*   **Язык программирования:** Python
*   **Основные библиотеки:**
    *   PyTorch
    *   Hugging Face Transformers (для моделей, токенизаторов, обучения)
    *   Hugging Face Datasets (для работы с данными)
    *   Pandas (для манипуляции данными)
    *   NLTK (для некоторых метрик и токенизации при оценке)
    *   Scikit-learn (для разделения данных)
    *   Rouge, BERT-Score (для метрик оценки)
*   **Среда разработки:** Jupyter Notebook 

## Структура Репозитория

*   `compute_metrics/`: Jupyter ноутбуки для расчета метрик и оценки различных чекпоинтов моделей.
    *   `compute_metrics_ruGPT3medium.ipynb`
    *   `compute_metrics_ruGPT3small.ipynb`
    *   `compute_metrics_ruT5.ipynb`
*   `data/`: Исходные файлы датасетов.
    *   `gazeta_raw.txt`
    *   `xl_sum_ru.jsonl`
*   `final_data/`: Обработанные датасеты, разделенные на обучающую, валидационную и тестовую выборки.
    *   `test.csv`
    *   `train.csv`
    *   `validation.csv`
*   `fit_models/`: Jupyter ноутбуки, содержащие код для дообучения (fine-tuning) моделей.
    *   `fit_rugpt3medium.ipynb`
    *   `fit_rugpt3small.ipynb`
    *   `fit_ruT5.ipynb`
*   `metrics/`: CSV файлы с результатами метрик для различных чекпоинтов моделей.
    *   `metrics_ruGPT3medium1.csv`
    *   `metrics_ruGPT3medium2.csv`
    *   `metrics_ruGPT3small.csv`
    *   `metrics_ruT5.csv`
*   `final_inference.ipynb`: Jupyter ноутбук для генерации примеров суммаризации с использованием всех моделей.
*   `prepare_dataset.ipynb`: Jupyter ноутбук для полной подготовки данных (загрузка, очистка, объединение, фильтрация, разделение).

## Основные Результаты

*   Модель `ruT5-base` (чекпоинт 20-й эпохи) показала наилучшие результаты по большинству автоматических метрик.
*   Качественный анализ подтвердил, что `ruT5-base` генерирует более фактически точные и релевантные резюме по сравнению с дообученными моделями `ruGPT3-small` и `ruGPT3-medium`, которые чаще проявляли склонность к "галлюцинациям".
*   Сравнение с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta` и `csebuetnlp/mT5_multilingual_XLSum`) показало, что дообученная `ruT5-base` достигает сопоставимого, а по некоторым метрикам и превосходящего уровня качества, даже при генерации более коротких резюме.

| Модель         | Лучший Чекпоинт | gen_len | rouge1_f | rouge2_f | rougel_f | bert_score_f1 | chrf++  | bleu    | meteor  |
|----------------|-------------------|---------|----------|----------|----------|---------------|---------|---------|---------|
| ruT5-base      | checkpoint-20     | 29.7094 | 30.7346  | 15.2225  | 27.9426  | 78.3572       | 40.0573 | 10.9116 | 29.4225 |
| ruGPT3-small   | checkpoint-40     | 18.2206 | 25.7682  | 11.9178  | 23.3153  | 75.6450       | 33.3899 | 9.5557  | 25.6184 |
| ruGPT3-medium  | checkpoint-20     | 23.2076 | 27.0257  | 12.5114  | 24.4839  | 76.1750       | 38.8347 | 10.7231 | 29.0458 |

## Возможные Улучшения и Дальнейшая Работа

*   Использование более крупных моделей.
*   Тонкая настройка гиперпараметров и стратегий декодирования.
*   Расширение и улучшение качества обучающих данных.
*   Применение техник для снижения "галлюцинаций" у GPT-моделей.
*   Проведение более масштабной человеческой оценки.


