# Абстрактная Суммаризация Русскоязычных Новостных Текстов с Использованием Seq2Seq Моделей

Этот репозиторий содержит материалы курсовой работы, посвященной исследованию и сравнению различных трансформерных моделей на основе архитектуры Sequence-to-Sequence для задачи абстрактной суммаризации новостных текстов на русском языке.

## Описание Проекта

Целью данной работы являлась разработка, обучение и оценка нескольких современных нейросетевых моделей для генерации кратких и информативных резюме русскоязычных новостных статей. Основное внимание было уделено абстрактивному подходу к суммаризации, при котором модель генерирует новый текст, а не просто извлекает фрагменты из оригинала.

**Ключевые этапы работы:**
1.  Анализ теоретических основ задачи суммаризации и архитектур Seq2Seq (T5, GPT, BART/mBART).
2.  Сбор, объединение и предобработка русскоязычных новостных датасетов (Gazeta и XLSum) для формирования обучающей, валидационной и тестовой выборок.
3.  Дообучение (fine-tuning) трех трансформерных моделей:
    *   `ai-forever/ruT5-base`
    *   `ai-forever/rugpt3small_based_on_gpt2`
    *   `sberbank-ai/rugpt3medium_based_on_gpt2`
4.  Количественная оценка качества сгенерированных резюме с использованием стандартных метрик (ROUGE, METEOR, BERTScore, BLEU, CHRF++).
5.  Качественный анализ полученных результатов и сравнение моделей между собой, а также с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta`, `csebuetnlp/mT5_multilingual_XLSum`).

## Технологический Стек

*   **Язык программирования:** Python
*   **Основные библиотеки:**
    *   PyTorch
    *   Hugging Face Transformers (для моделей, токенизаторов, обучения)
    *   Hugging Face Datasets (для работы с данными)
    *   Pandas (для манипуляции данными)
    *   NLTK (для некоторых метрик и токенизации при оценке)
    *   Scikit-learn (для разделения данных)
    *   Rouge, BERT-Score (для метрик оценки)
*   **Среда разработки:** Jupyter Notebook (Google Colab для обучения на GPU)

## Структура Репозитория

*   `data/`: Директория для хранения исходных и обработанных датасетов (может быть исключена из Git через `.gitignore`, если файлы большие).
    *   `final_data/`: Содержит `train.csv`, `validation.csv`, `test.csv`.
*   `notebooks/`: Jupyter ноутбуки с кодом для каждого этапа работы.
    *   `01_data_preparation.ipynb`: Загрузка, очистка, объединение и фильтрация данных.
    *   `02_train_ruT5_base.ipynb`: Обучение модели ruT5-base.
    *   `03_train_ruGPT3_small.ipynb`: Обучение модели ruGPT3-small.
    *   `04_train_ruGPT3_medium.ipynb`: Обучение модели ruGPT3-medium.
    *   `05_evaluation.ipynb`: Оценка всех моделей, расчет метрик, генерация примеров.
*   `models/`: Директория для сохранения дообученных моделей (чекпоинтов) (может быть исключена из Git).
*   `results/`: Результаты оценки, таблицы с метриками, графики.
*   `src/` (опционально): Вспомогательные скрипты или функции, если они вынесены из ноутбуков.
*   `README.md`: Этот файл.
*   `requirements.txt`: Список зависимостей для установки.
*   `final_course_paper.pdf`: Текст пояснительной записки к курсовой работе (ваш документ).

## Как Запустить (Основные Шаги)

1.  **Клонировать репозиторий:**
    ```bash
    git clone [URL вашего репозитория]
    cd [название репозитория]
    ```
2.  **Установить зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Подготовить данные:**
    *   Загрузить исходные датасеты `gazeta_raw.txt` и `xl_sum_ru.jsonl` в директорию `data/` (или указать пути в ноутбуке `01_data_preparation.ipynb`).
    *   Запустить ноутбук `01_data_preparation.ipynb` для генерации файлов `train.csv`, `validation.csv`, `test.csv` в `data/final_data/`.
4.  **Обучить модели (опционально, если не используете предобученные чекпоинты):**
    *   Запустить соответствующие ноутбуки `02_train_*.ipynb`, `03_train_*.ipynb`, `04_train_*.ipynb`. Это потребует наличия GPU и может занять значительное время. Сохраненные чекпоинты будут в директории `models/`.
5.  **Провести оценку:**
    *   Убедитесь, что у вас есть дообученные модели (или используйте пути к ним на Hugging Face, если они загружены) и тестовый датасет `test.csv`.
    *   Запустить ноутбук `05_evaluation.ipynb` для генерации предсказаний, расчета метрик и анализа результатов.

## Основные Результаты

*   Модель `ruT5-base` (чекпоинт 20-й эпохи) показала наилучшие результаты по большинству автоматических метрик (ROUGE-1 F1 ~30.7, ROUGE-2 F1 ~15.2, METEOR ~29.4).
*   Качественный анализ подтвердил, что `ruT5-base` генерирует более фактически точные и релевантные резюме по сравнению с дообученными моделями `ruGPT3-small` и `ruGPT3-medium`, которые чаще проявляли склонность к "галлюцинациям".
*   Сравнение с контрольными моделями (`IlyaGusev/mbart_ru_sum_gazeta` и `csebuetnlp/mT5_multilingual_XLSum`) показало, что дообученная `ruT5-base` достигает сопоставимого, а по некоторым метрикам и превосходящего уровня качества, даже при генерации более коротких резюме.

*(Здесь можно вставить вашу таблицу с итоговыми метриками или ссылку на нее)*

## Возможные Улучшения и Дальнейшая Работа

*   Использование более крупных моделей.
*   Тонкая настройка гиперпараметров и стратегий декодирования.
*   Расширение и улучшение качества обучающих данных.
*   Применение техник для снижения "галлюцинаций" у GPT-моделей.
*   Проведение более масштабной человеческой оценки.

## Ссылка на Текст Курсовой Работы

[final_course_paper.pdf](final_course_paper.pdf) *(Замените на актуальное имя файла, если оно другое)*

---
